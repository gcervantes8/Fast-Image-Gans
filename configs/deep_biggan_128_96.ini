[MODEL]
# Each run will get it's own unique id and folder in the output directory
model_name = myFirstModel
models_dir = models

[DATA]
# Directory it will train the GAN with
train_dir = data/coil-100

# Aspect Ratio is base width : base height
# Upsample layer of 5, base_with 4, base_height 3 is an image of size 128 x 96
base_width = 4
base_height = 3
# Raising the upsample_layer will double the image height and width, and reducing by 1 will halve the image size
upsample_layers = 5

# Number of channels in the training images. For color images this is 3
num_channels = 3
batch_size = 32

# Number of workers for data-loader
workers = 7

[MACHINE]
# Number of GPUs available. Use 0 for CPU mode.
ngpu = 1

[TRAIN]
num_epochs = 1000

# Applies gradient accumulations, pseudo batch size will be batch_size * accumulation_iterations
accumulation_iterations = 1

mixed_precision = True

# Saves model and fake images, if set to 0, will save every epoch
save_steps = 500

log_steps = 100

# Loss function options: [hinge, mse, bce]
loss_function = hinge

# Learning rates
generator_lr = 0.00005
discriminator_lr = 0.0002

# [Disabled] Trains the discriminator twice before training the generator
two_d_steps_per_g = False

# Beta1 hyper-param for Adam optimizers
beta1 = 0.0
beta2 = 0.999

[MODEL ARCHITECTURE]

# Options: [deep-biggan, biggan, dcgan]
model_type = deep-biggan

# Size of z latent vector (generator input)
latent_vector_size = 128

# Size of feature maps in generator
ngf = 16

# Size of feature maps in discriminator
ndf = 16

# Whether to use Exponential Moving Averages
generator_ema = True
ema_decay = 0.9999

# Orthogonal Regularization - Value of 0 will disable
orthogonal_value = 0.0001

# Truncation Value - Value of 0 will disable
truncation_value = 0.75

[METRICS]
# Will run the metric every steps_to_eval amount of steps, if set to 0, will run the metric every epoch
steps_to_eval = 1000

is_metric = False
fid_metric = False
