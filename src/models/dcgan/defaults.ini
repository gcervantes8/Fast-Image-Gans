[DATA]
# Number of channels in the training images. For color images this is 3
num_channels = 3
batch_size = 32

# Number of workers for data-loader
workers = 7

[TRAIN]
num_epochs = 1000

# Applies gradient accumulations, pseudo-batch size will be batch_size * accumulation_iterations
accumulation_iterations = 1

mixed_precision = False

# Requires PyTorch 2.0
compile = False

channels_last = False

# Saves model and fake images, if set to 0, will save every epoch
save_steps = 500

log_steps = 100

# Loss function options: [hinge, mse, bce]
loss_function = bce

# Learning rates
generator_lr = 0.0002
discriminator_lr = 0.0002

# Beta1 hyper-param for Adam optimizers
beta1 = 0.5
beta2 = 0.999

# Weight decay
discriminator_wd = 0.0
generator_wd = 0.0

[MODEL ARCHITECTURE]
# Options: [deep-biggan, biggan, dcgan]
model_type = dcgan

# Size of z latent vector (generator input)
latent_vector_size = 100

# Size of feature maps in generator
ngf = 32

# Size of feature maps in discriminator
ndf = 32

# Whether to use Exponential Moving Averages
generator_ema = False
ema_decay = 0.9999

# Orthogonal Regularization - Value of 0 will disable
orthogonal_value = 0.0

# Truncation Value - Value of 0 will disable
truncation_value = 0

# Type of loss to train with.  Options are [adversarial, omni-loss]
loss_type = adversarial

[METRICS]
# Will run the metric every steps_to_eval amount of steps, if set to 0, will run the metric every epoch
steps_to_eval = 1000

# How many images to use for evaluation. Most papers use a value of 50k
n_images_to_eval = 5000

is_metric = False
fid_metric = False
