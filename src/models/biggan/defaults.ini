[DATA]
# Number of channels in the training images. For color images this is 3
num_channels = 3
batch_size = 32

# Number of workers for data-loader
workers = 7

[TRAIN]
num_epochs = 1000

# Saves model and fake images every save_steps
save_steps = 2000

log_steps = 100

# Applies gradient accumulations, pseudo-batch size will be batch_size * accumulation_iterations
accumulation_iterations = 1

mixed_precision = False

# Requires PyTorch 2.0
compile = False

channels_last = False

# Loss function options: [hinge, mse, bce]
loss_function = hinge

# Learning rates
generator_lr = 0.00005
discriminator_lr = 0.0002

# Beta1 hyper-param for Adam optimizers
beta1 = 0.0
beta2 = 0.999

# Weight decay
discriminator_wd = 0.0
generator_wd = 0.0

[MODEL ARCHITECTURE]
# Options: [deep-biggan, biggan, dcgan]
model_type = biggan

# Size of z latent vector (generator input)
latent_vector_size = 120

# Size of feature maps in generator
ngf = 32

# Size of feature maps in discriminator
ndf = 32

# Whether to use Exponential Moving Averages
generator_ema = True
ema_decay = 0.9999

# Orthogonal Regularization - Value of 0 will disable
orthogonal_value = 0.0001

# Truncation Value - Value of 0 will disable
truncation_value = 0.5

# Type of loss to train with.  Options are [adversarial, omni-loss]
loss_type = adversarial

[METRICS]
# Will run the metric every steps_to_eval amount of steps
steps_to_eval = 1000

# How many images to use for evaluation. Most papers use a value of 50k
n_images_to_eval = 5000

is_metric = False
fid_metric = False
