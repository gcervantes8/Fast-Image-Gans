[MODEL]
# Each run will get it's own unique id and folder in the output directory
model_name = myFirstModel
models_dir = models

[DATA]
# Directory it will train the GAN with
train_dir = data/coil-100

# All images will be resized to this
image_width = 128
image_height = 128

# Number of channels in the training images. For color images this is 3
num_channels = 3
batch_size = 32

# Number of workers for data-loader
workers = 7

[MACHINE]
# Number of GPUs available. Use 0 for CPU mode.
ngpu = 1

[TRAIN]
num_epochs = 1000

# [Disabled] Applies gradient accumulations, pseudo batch size will be batch_size * accumulation_iterations
accumulation_iterations = 1

mixed_precision = True

# Saves model and fake images, if set to 0, will save every epoch
save_steps = 500

log_steps = 100

# Loss function options: [hinge, mse, bce]
loss_function = hinge

# Learning rates
generator_lr = 0.00005
discriminator_lr = 0.0002

# [Disabled] Trains the discriminator twice before training the generator
two_d_steps_per_g = True

# Beta1 hyper-param for Adam optimizers
beta1 = 0.0
beta2 = 0.999

[MODEL ARCHITECTURE]

# Options: [deep-biggan, biggan, dcgan]
model_type = deep-biggan

# Size of z latent vector (generator input)
latent_vector_size = 128

# Size of feature maps in generator
ngf = 16

# Size of feature maps in discriminator
ndf = 16

# Whether to use Exponential Moving Averages
generator_ema = False
ema_decay = 0.9999

[METRICS]
# Will run the metric every steps_to_eval amount of steps, if set to 0, will run the metric every epoch
steps_to_eval = 1000

is_metric = False
fid_metric = False
